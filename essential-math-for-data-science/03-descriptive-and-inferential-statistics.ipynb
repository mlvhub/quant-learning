{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d5ba92",
   "metadata": {},
   "source": [
    "# Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373ed2f",
   "metadata": {},
   "source": [
    "### Population\n",
    "\n",
    "A _population_ is a particular group of interest we want to study, such as “all seniors over the age of 65 in the North America,” “all golden retrievers in Scotland,” or “current high school sophomores at Los Altos High School.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27b027",
   "metadata": {},
   "source": [
    "### Sample\n",
    "\n",
    "A _sample_ is a subset of the population that is ideally random and unbiased, which we use to infer attributes about the population. We often have to study samples because polling the entire population is not always possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c5cfa",
   "metadata": {},
   "source": [
    "### Bias\n",
    "\n",
    "The way to overcome bias is to truly at random select students (in the example study) from the entire population, and they cannot elect themselves into or out of the sample voluntarily.\n",
    "\n",
    "There are many types of bias, but they all have the same effect of distorting findings.\n",
    "\n",
    "_Confirmation bias_ is gathering only data that supports your belief, which can even be done unknowingly. An example of this is following only social media accounts you politically agree with, reinforcing your beliefs rather than challenging them.\n",
    "\n",
    "_Self-selection bias_ is when certain types of subjects are more likely to include themselves in the experiment. Walking onto a flight and polling the customers if they like the airline over other airlines, and using that to rank customer satisfaction among all airlines, is silly. Why? Many of those customers are likely repeat customers, and they have created self-selection bias.\n",
    "\n",
    "_Survival bias_ captures only living and survived subjects, while the deceased ones are never accounted for.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98b048",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67265598",
   "metadata": {},
   "source": [
    "### Mean and Weighted Mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e38f153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.875"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pets each person owns\n",
    "sample = [1, 3, 2, 5, 7, 0, 2, 3]\n",
    "\n",
    "mean = sum(sample) / len(sample)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7519730d",
   "metadata": {},
   "source": [
    "The mean we commonly use (above) gives equal importance to each value. But we can manipulate the mean and give each item a different weight:\n",
    "\n",
    "$$\n",
    "\\text{Weighted mean} = \\frac{(x_1 \\cdot w_1) + (x_2 \\cdot w_2) + (x_3 \\cdot w_3) + \\ldots + (x_n \\cdot w_n)}{w_1 + w_2 + w_3 + \\ldots + w_n}\n",
    "$$\n",
    "\n",
    "This can be helpful when we want some values to contribute to the mean more than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64700f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three exams of .20 weight each and final exam of .40 weight\n",
    "sample = [90, 80, 63, 87]\n",
    "weights = [.20, .20, .20, .40]\n",
    "\n",
    "weighted_mean = sum(s * w for s,w in zip(sample, weights)) / sum(weights)\n",
    "weighted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841837b3",
   "metadata": {},
   "source": [
    "### Median\n",
    "\n",
    "The median is the middlemost value in a set of ordered values. You sequentially order the values, and the median will be the centermost value. If you have an even number of values, you average the two centermost values.\n",
    "\n",
    "The median can be preferable in outlier-heavy situations (such as income-related data) over the mean, when your median is very different from your mean, that means you have a skewed dataset with outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984e5c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pets each person owns\n",
    "sample = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def median(values):\n",
    "    ordered = sorted(values)\n",
    "    n = len(ordered)\n",
    "    mid = int(n / 2) - 1 if n % 2 == 0 else int(n/2)\n",
    "\n",
    "    if n % 2 == 0:\n",
    "        return (ordered[mid] + ordered[mid+1]) / 2.0\n",
    "    else:\n",
    "        return ordered[mid]\n",
    "\n",
    "median(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4754f23",
   "metadata": {},
   "source": [
    "### Mode\n",
    "\n",
    "The mode is the most frequently occurring set of values. It primarily becomes useful when your data is repetitive and you want to find which values occur the most frequently.\n",
    "\n",
    "When no value occurs more than once, there is no mode. When two values occur with an equal amount of frequency, then the dataset is considered _bimodal_.\n",
    "\n",
    "In practicality, the mode is not used a lot unless your data is repetitive. This is commonly encountered with integers, categories, and other discrete variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88be51b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pets each person owns\n",
    "from collections import defaultdict\n",
    "\n",
    "sample = [1, 3, 2, 5, 7, 0, 2, 3]\n",
    "\n",
    "def mode(values):\n",
    "    counts = defaultdict(lambda: 0)\n",
    "\n",
    "    for s in values:\n",
    "        counts[s] += 1\n",
    "\n",
    "    max_count = max(counts.values())\n",
    "    modes = [v for v in set(values) if counts[v] == max_count]\n",
    "    return modes\n",
    "\n",
    "mode(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bfdaa",
   "metadata": {},
   "source": [
    "### Variance and Standard Deviation\n",
    "\n",
    "The _variance_ is a measure of how spread out our data is.\n",
    "\n",
    "#### Population Variance and Standard Deviation\n",
    "\n",
    "$$\n",
    "\\text{Population variance} = \\frac{(x_1 - mean)^2 + (x_2 - mean)^2 + \\ldots + (x_n - mean)^2}{N}\n",
    "$$\n",
    "\n",
    "More formally:\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{\\sum(x_i - \\mu)^2}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92908b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.387755102040813"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pets each person owns\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def variance(values):\n",
    "    mean = sum(values) / len(values)\n",
    "    _variance = sum((v - mean) ** 2 for v in values) / len(values)\n",
    "    return _variance\n",
    "\n",
    "variance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ce4fd",
   "metadata": {},
   "source": [
    "So the variance for number of pets owned by my office staff is 21.387755. OK, but what does it exactly mean?\n",
    "\n",
    "This number is larger than any of our observations because we did a lot squaring and summing, putting it on an entirely different metric. So how do we squeeze it back down so it’s back on the scale we started with?\n",
    "\n",
    "Let’s take the square root of the variance, which gives us the _standard deviation_.\n",
    "\n",
    "This is the variance scaled into a number expressed in terms of “number of pets,” which makes it a bit more meaningful:\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{\\sum(x_i - \\mu)^2}{N}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e173e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.624689730353898"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def std_dev(values):\n",
    "    return sqrt(variance(values))\n",
    "\n",
    "std_dev(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3363de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
